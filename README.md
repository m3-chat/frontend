<p align="center">
  <a href="https://m3-chat.vercel.app">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/37242413-0907-4dfa-b5e9-feb28ed9d778">
      <img src="https://github.com/user-attachments/assets/37242413-0907-4dfa-b5e9-feb28ed9d778" height="128">
    </picture>
    <h1 align="center">M3 Chat</h1>
  </a>
</p>

<p align="center">
  <a href="https://m3-chat.vercel.app">
    <img src="https://deploy-badge.vercel.app/vercel/m3-chat?style=for-the-badge&name=Vercel&labelColor=000000&color=" alt="">
  </a>
  <a href="./LICENSE"><img src="https://img.shields.io/github/license/m3-chat/frontend?logo=github&style=for-the-badge&labelColor=000000&color=" alt="License: AGPL v3"></a>
  <a href="https://discord.gg/8aNqjKFb"><img alt="Discord" src="https://img.shields.io/discord/1384581817755238430?logo=discord&style=for-the-badge&labelColor=000000&color="></a>
  <a href="https://github.com/orgs/m3-chat/discussions">
    <img src="https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&logo=github&labelColor=000000&logoWidth=20&logoColor=white">
  </a>
</p>

M3 Chat is an OSS AI chat service that's completely free, private, actively maintained and built with Next.js

### Why use M3 Chat?
Most AI chat web app services are slow, expensive, or require accounts (with heavy message limits). M3 Chat is an open-source, free, no account required, AI chat web app with unlimited messages.
I'm currently running all models on a **Mac Studio M3 Ultra** (which is why it's named **M3** chat) using [Ollama](https://ollama.com).

## Models
- [x] LLaMA 3 8B (General Purpose) — `llama3:8b`
- [x] LLaMA 2 (Uncensored) — `llama2-uncensored`
- [x] Gemma 3 (General Purpose) — `gemma3`
- [x] Gemma (General Purpose) — `gemma`
- [x] Phi-3 Mini (Fastest) — `phi3:mini`
- [x] Mistral 7B (Balanced) — `mistral`
- [x] OpenCoder 8B (Code) - `opencoder:8b`
- [x] Gemma 2B (Tiny + Reasonable) — `gemma:2b`
- [x] Gemma 7B (Chat Capable) — `gemma:7b`
- [x] Qwen 1.5 7B (Chat & Reasoning) — `qwen:7b`
- [x] Qwen 2.5 Coder (Code) — `qwen2.5-coder`
- [x] Qwen 3 (General Purpose) — `qwen3`
- [x] DeepSeek Coder 6.7B (Code) — `deepseek-coder:6.7b`
- [x] DeepSeek V2 16B (General Purpose) — `deepseek-v2:16b`
- [x] Dolphin Mistral 7B (Uncensored, Code) — `dolphin-mistral:7b`
- [x] Dolphin 3 8B (General Purpose) — `dolphin3`
- [x] StarCoder2 7B (Coding) — `starcoder2:7b`
- [x] Magistral (Reasoning) — `magistral`
- [x] Devstral (Code) — `devstral`

## Contributing
M3 Chat is open to contributions, suggestions, or any feedback!
